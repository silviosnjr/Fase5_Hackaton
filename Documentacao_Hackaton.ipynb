{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackaton | IA para Devs | Fase 5\n",
    "- Silvio Sales do Nascimento Junior (RM 353303)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentação do Fluxo de Desenvolvimento da Solução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import mimetypes\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from ultralytics import YOLO  # Utilizando YOLOv8 para detecção de objetos\n",
    "from smtplib import SMTP\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.image import MIMEImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução\n",
    "Esta solução foi desenvolvida para processar vídeos e detectar a presença de objetos cortantes, como facas e tesouras, utilizando o modelo YOLOv8. Ao detectar um objeto, a imagem correspondente é capturada e enviada via e-mail para um destinatário predefinido.\n",
    "\n",
    "### Passo a Passo\n",
    "\n",
    "1. **Carregamento do Modelo**\n",
    "   - O modelo YOLOv8 é carregado para identificar objetos em imagens extraídas de um vídeo.\n",
    "\n",
    "2. **Criação da Pasta para Armazenamento de Frames**\n",
    "   - Criamos uma pasta chamada `frames_detectados` para armazenar os frames que contenham objetos suspeitos.\n",
    "\n",
    "3. **Comparação de Imagens**\n",
    "   - Implementamos a métrica `Structural Similarity Index (SSIM)` para evitar a captura e envio de imagens muito semelhantes.\n",
    "\n",
    "4. **Detecção de Objetos**\n",
    "   - Utilizamos YOLO para verificar se há objetos cortantes nas imagens extraídas.\n",
    "\n",
    "5. **Envio de Alerta por E-mail**\n",
    "   - Caso um objeto cortante seja detectado, um e-mail é enviado com a imagem anexada.\n",
    "\n",
    "6. **Processamento de Vídeo**\n",
    "   - O vídeo é lido frame a frame, aplicando a lógica de detecção e envio de alerta sempre que necessário.\n",
    "\n",
    "### Código Fonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo treinado\n",
    "yolo_model = YOLO(\"modelo_treinado.pt\")\n",
    "\n",
    "# Criar pasta para armazenar frames detectados\n",
    "output_folder = \"frames_detectados\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Variáveis globais para armazenar o último frame detectado e sua imagem\n",
    "last_detected_image = None  # Matriz NumPy do último frame salvo\n",
    "\n",
    "detection_log = []  # Lista para armazenar registros de detecção"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para calcular a similaridade entre dois frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar(image1, image2, threshold=0.90):\n",
    "    \"\"\"Compara duas imagens e retorna True se forem muito semelhantes.\"\"\"\n",
    "    if image1 is None or image2 is None:\n",
    "        return False  # Primeira imagem, sempre aceitar\n",
    "\n",
    "    # Convertendo imagens para tons de cinza\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Redimensionando para garantir tamanhos iguais\n",
    "    gray1 = cv2.resize(gray1, (gray2.shape[1], gray2.shape[0]))\n",
    "\n",
    "    # Calculando a similaridade entre as imagens\n",
    "    score, _ = ssim(gray1, gray2, full=True)\n",
    "    return score >= threshold  # Retorna True se forem muito semelhantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para processar imagem e detectar objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_objetos(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    results = yolo_model(image)\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls = result.names[int(box.cls[0])]\n",
    "            if cls in [\"knife\", \"scissors\"]:  # Ajuste para as classes do dataset\n",
    "                return True  # Objeto cortante detectado\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para enviar alerta por e-mail com anexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enviar_alerta(image_path, tempo):\n",
    "    sender = \"silviosnjr@yahoo.com.br\"\n",
    "    receiver = \"silviosnjr@gmail.com\"\n",
    "    subject = \"Alerta de Segurança: Objeto Cortante Detectado\"\n",
    "    body = f\"Objeto cortante detectado no tempo {tempo} Veja a imagem em anexo.\"\n",
    "\n",
    "    # Criando e-mail com suporte para anexos\n",
    "    msg = MIMEMultipart()\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender\n",
    "    msg[\"To\"] = receiver\n",
    "    msg.attach(MIMEText(body, \"plain\"))\n",
    "\n",
    "    # Anexando a imagem\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            img_data = img_file.read()\n",
    "            mime_type, _ = mimetypes.guess_type(image_path)\n",
    "            if mime_type is None:\n",
    "                mime_type = \"application/octet-stream\"\n",
    "\n",
    "            main_type, sub_type = mime_type.split(\"/\", 1)\n",
    "            img_attachment = MIMEImage(img_data, _subtype=sub_type)\n",
    "            img_attachment.add_header(\"Content-Disposition\", f\"attachment; filename={os.path.basename(image_path)}\")\n",
    "            msg.attach(img_attachment)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao anexar a imagem: {e}\")\n",
    "        return\n",
    "\n",
    "    # Configuração do servidor SMTP do Yahoo\n",
    "    smtp_server = \"smtp.mail.yahoo.com\"\n",
    "    smtp_port = 587  # Usando TLS\n",
    "    # email_password = os.getenv(\"SENHA_YAHOO\")  # Obtendo senha do ambiente\n",
    "    email_password = \"wvuyhfbfdxumjtwh\"\n",
    "\n",
    "    try:\n",
    "        with SMTP(smtp_server, smtp_port) as server:\n",
    "            server.starttls()  # Ativa criptografia TLS\n",
    "            server.login(sender, email_password)  # Login com e-mail e senha de app\n",
    "            server.sendmail(sender, receiver, msg.as_string())\n",
    "        print(\"Alerta enviado com sucesso!\")\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao enviar e-mail:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processamento de vídeo gravado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 116.5ms\n",
      "Speed: 2.4ms preprocess, 116.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cup, 109.4ms\n",
      "Speed: 1.8ms preprocess, 109.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 139.7ms\n",
      "Speed: 1.9ms preprocess, 139.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 133.0ms\n",
      "Speed: 2.6ms preprocess, 133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 133.6ms\n",
      "Speed: 2.8ms preprocess, 133.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 174.5ms\n",
      "Speed: 4.6ms preprocess, 174.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 170.4ms\n",
      "Speed: 3.7ms preprocess, 170.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cup, 169.3ms\n",
      "Speed: 3.7ms preprocess, 169.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 167.1ms\n",
      "Speed: 5.3ms preprocess, 167.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 147.3ms\n",
      "Speed: 1.9ms preprocess, 147.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 145.8ms\n",
      "Speed: 2.3ms preprocess, 145.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 119.1ms\n",
      "Speed: 2.0ms preprocess, 119.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 188.3ms\n",
      "Speed: 1.9ms preprocess, 188.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 126.8ms\n",
      "Speed: 2.4ms preprocess, 126.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 130.9ms\n",
      "Speed: 2.3ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 110.4ms\n",
      "Speed: 3.2ms preprocess, 110.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 193.0ms\n",
      "Speed: 2.8ms preprocess, 193.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 168.0ms\n",
      "Speed: 6.7ms preprocess, 168.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.1ms\n",
      "Speed: 2.5ms preprocess, 120.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 149.4ms\n",
      "Speed: 2.6ms preprocess, 149.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 171.9ms\n",
      "Speed: 1.9ms preprocess, 171.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.1ms\n",
      "Speed: 3.6ms preprocess, 123.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 129.3ms\n",
      "Speed: 2.6ms preprocess, 129.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 163.6ms\n",
      "Speed: 2.7ms preprocess, 163.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 149.2ms\n",
      "Speed: 3.3ms preprocess, 149.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 motorcycle, 150.3ms\n",
      "Speed: 2.1ms preprocess, 150.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 118.4ms\n",
      "Speed: 2.2ms preprocess, 118.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 114.8ms\n",
      "Speed: 2.1ms preprocess, 114.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 116.2ms\n",
      "Speed: 1.6ms preprocess, 116.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.5ms\n",
      "Speed: 2.7ms preprocess, 113.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.8ms\n",
      "Speed: 2.2ms preprocess, 112.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.2ms\n",
      "Speed: 2.4ms preprocess, 120.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 122.5ms\n",
      "Speed: 2.2ms preprocess, 122.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.0ms\n",
      "Speed: 1.7ms preprocess, 113.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 126.5ms\n",
      "Speed: 1.9ms preprocess, 126.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.7ms\n",
      "Speed: 2.0ms preprocess, 125.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 119.7ms\n",
      "Speed: 2.1ms preprocess, 119.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 113.2ms\n",
      "Speed: 2.9ms preprocess, 113.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 115.9ms\n",
      "Speed: 1.9ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.2ms\n",
      "Speed: 2.1ms preprocess, 120.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 118.6ms\n",
      "Speed: 3.2ms preprocess, 118.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 134.4ms\n",
      "Speed: 2.8ms preprocess, 134.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 132.8ms\n",
      "Speed: 2.3ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 113.9ms\n",
      "Speed: 1.6ms preprocess, 113.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 motorcycle, 130.6ms\n",
      "Speed: 1.6ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 114.5ms\n",
      "Speed: 4.2ms preprocess, 114.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 113.2ms\n",
      "Speed: 2.2ms preprocess, 113.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.1ms\n",
      "Speed: 2.2ms preprocess, 111.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 114.2ms\n",
      "Speed: 1.9ms preprocess, 114.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.2ms\n",
      "Speed: 2.5ms preprocess, 116.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.6ms\n",
      "Speed: 2.1ms preprocess, 121.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.2ms\n",
      "Speed: 2.5ms preprocess, 116.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 111.1ms\n",
      "Speed: 2.2ms preprocess, 111.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 108.9ms\n",
      "Speed: 2.9ms preprocess, 108.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 118.7ms\n",
      "Speed: 1.7ms preprocess, 118.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 116.8ms\n",
      "Speed: 1.9ms preprocess, 116.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 119.4ms\n",
      "Speed: 3.1ms preprocess, 119.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.9ms\n",
      "Speed: 2.7ms preprocess, 113.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.8ms\n",
      "Speed: 2.3ms preprocess, 114.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 136.7ms\n",
      "Speed: 2.2ms preprocess, 136.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.7ms\n",
      "Speed: 2.3ms preprocess, 113.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.7ms\n",
      "Speed: 2.9ms preprocess, 113.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.9ms\n",
      "Speed: 2.4ms preprocess, 109.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.1ms\n",
      "Speed: 2.0ms preprocess, 116.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 110.8ms\n",
      "Speed: 2.9ms preprocess, 110.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 112.4ms\n",
      "Speed: 2.3ms preprocess, 112.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 113.2ms\n",
      "Speed: 2.5ms preprocess, 113.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 112.1ms\n",
      "Speed: 2.7ms preprocess, 112.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 motorcycle, 135.9ms\n",
      "Speed: 2.3ms preprocess, 135.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.7ms\n",
      "Speed: 2.3ms preprocess, 124.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 153.6ms\n",
      "Speed: 2.4ms preprocess, 153.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 173.8ms\n",
      "Speed: 3.0ms preprocess, 173.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 forks, 144.5ms\n",
      "Speed: 3.2ms preprocess, 144.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 forks, 131.3ms\n",
      "Speed: 2.8ms preprocess, 131.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 forks, 1 dining table, 148.7ms\n",
      "Speed: 2.3ms preprocess, 148.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 forks, 1 dining table, 129.5ms\n",
      "Speed: 2.7ms preprocess, 129.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 forks, 1 dining table, 125.5ms\n",
      "Speed: 2.4ms preprocess, 125.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 forks, 1 dining table, 237.7ms\n",
      "Speed: 2.9ms preprocess, 237.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 forks, 1 dining table, 1 cell phone, 122.5ms\n",
      "Speed: 1.8ms preprocess, 122.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 forks, 1 cell phone, 121.9ms\n",
      "Speed: 2.1ms preprocess, 121.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 forks, 1 cell phone, 110.2ms\n",
      "Speed: 2.8ms preprocess, 110.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 fork, 1 cell phone, 117.3ms\n",
      "Speed: 2.5ms preprocess, 117.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 forks, 1 cell phone, 108.6ms\n",
      "Speed: 2.7ms preprocess, 108.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 forks, 1 cell phone, 100.7ms\n",
      "Speed: 2.2ms preprocess, 100.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 forks, 1 knife, 1 cell phone, 103.2ms\n",
      "Speed: 2.4ms preprocess, 103.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Objeto cortante detectado! Frame salvo em frames_detectados\\frame_1739795872.jpg - Tempo: 2.83s\n",
      "Alerta enviado com sucesso!\n",
      "\n",
      "0: 384x640 2 persons, 2 forks, 1 cell phone, 123.2ms\n",
      "Speed: 3.8ms preprocess, 123.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 forks, 1 cell phone, 118.6ms\n",
      "Speed: 3.3ms preprocess, 118.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 forks, 1 knife, 1 dining table, 2 cell phones, 1 scissors, 119.5ms\n",
      "Speed: 1.8ms preprocess, 119.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Objeto cortante detectado! Frame salvo em frames_detectados\\frame_1739795877.jpg - Tempo: 2.93s\n",
      "Alerta enviado com sucesso!\n",
      "Frame muito semelhante ao anterior, ignorado.\n",
      "\n",
      "0: 384x640 2 persons, 2 forks, 1 knife, 3 scissorss, 111.5ms\n",
      "Speed: 2.2ms preprocess, 111.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Objeto cortante detectado! Frame salvo em frames_detectados\\frame_1739795883.jpg - Tempo: 3.00s\n",
      "Alerta enviado com sucesso!\n",
      "\n",
      "0: 384x640 2 persons, 2 forks, 1 knife, 3 scissorss, 187.1ms\n",
      "Speed: 2.8ms preprocess, 187.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Objeto cortante detectado! Frame salvo em frames_detectados\\frame_1739795887.jpg - Tempo: 3.03s\n",
      "Alerta enviado com sucesso!\n",
      "\n",
      "0: 384x640 2 persons, 2 forks, 1 knife, 1 scissors, 105.5ms\n",
      "Speed: 3.2ms preprocess, 105.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Objeto cortante detectado! Frame salvo em frames_detectados\\frame_1739795895.jpg - Tempo: 3.07s\n",
      "Alerta enviado com sucesso!\n",
      "\n",
      "0: 384x640 3 persons, 2 forks, 1 scissors, 135.8ms\n",
      "Speed: 3.9ms preprocess, 135.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Objeto cortante detectado! Frame salvo em frames_detectados\\frame_1739795900.jpg - Tempo: 3.10s\n",
      "Alerta enviado com sucesso!\n",
      "\n",
      "0: 384x640 4 persons, 1 fork, 1 cell phone, 1 scissors, 188.3ms\n",
      "Speed: 2.3ms preprocess, 188.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Objeto cortante detectado! Frame salvo em frames_detectados\\frame_1739795904.jpg - Tempo: 3.13s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m     last_detected_image \u001b[38;5;241m=\u001b[39m frame  \u001b[38;5;66;03m# Atualiza a última imagem detectada\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjeto cortante detectado! Frame salvo em \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Tempo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     \u001b[43menviar_alerta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{timestamp:.2f}\u001b[39;49;00m\u001b[38;5;124;43m segundos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(image_path)  \u001b[38;5;66;03m# Remove o frame salvo se não houver detecção\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[50], line 40\u001b[0m, in \u001b[0;36menviar_alerta\u001b[1;34m(image_path, tempo)\u001b[0m\n\u001b[0;32m     38\u001b[0m         server\u001b[38;5;241m.\u001b[39mstarttls()  \u001b[38;5;66;03m# Ativa criptografia TLS\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         server\u001b[38;5;241m.\u001b[39mlogin(sender, email_password)  \u001b[38;5;66;03m# Login com e-mail e senha de app\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m         \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msendmail\u001b[49m\u001b[43m(\u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreceiver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlerta enviado com sucesso!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Silvio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\smtplib.py:870\u001b[0m, in \u001b[0;36mSMTP.sendmail\u001b[1;34m(self, from_addr, to_addrs, msg, mail_options, rcpt_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m mail_options:\n\u001b[0;32m    869\u001b[0m         esmtp_opts\u001b[38;5;241m.\u001b[39mappend(option)\n\u001b[1;32m--> 870\u001b[0m (code, resp) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_addr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mesmtp_opts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m250\u001b[39m:\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m421\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Silvio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\smtplib.py:546\u001b[0m, in \u001b[0;36mSMTP.mail\u001b[1;34m(self, sender, options)\u001b[0m\n\u001b[0;32m    544\u001b[0m     optionlist \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(options)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputcmd(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmail\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFROM:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (quoteaddr(sender), optionlist))\n\u001b[1;32m--> 546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetreply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Silvio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\smtplib.py:398\u001b[0m, in \u001b[0;36mSMTP.getreply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Silvio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Silvio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Silvio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_path = \"videos/video.mp4\"  # Substituir pelo caminho do vídeo\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)  # Obtém a taxa de frames por segundo\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Armazendo frame\n",
    "    frame_count += 1\n",
    "    timestamp = frame_count / frame_rate  # Calcula o tempo em segundos no vídeo\n",
    "    image_path = os.path.join(output_folder, f\"frame_{int(time.time())}.jpg\")\n",
    "\n",
    "    # Evitar salvar e-mails para frames semelhantes\n",
    "    if last_detected_image is None or not is_similar(last_detected_image, frame, threshold=0.90):\n",
    "        cv2.imwrite(image_path, frame)\n",
    "\n",
    "        if detectar_objetos(image_path):\n",
    "            detection_log.append(f\"Objeto detectado no tempo: {timestamp:.2f} segundos\")\n",
    "            last_detected_image = frame  # Atualiza a última imagem detectada\n",
    "            print(f\"Objeto cortante detectado! Frame salvo em {image_path} - Tempo: {timestamp:.2f}s\")\n",
    "            enviar_alerta(image_path, \"{timestamp:.2f} segundos\")\n",
    "        else:\n",
    "            os.remove(image_path)  # Remove o frame salvo se não houver detecção\n",
    "    else:\n",
    "        print(\"Frame muito semelhante ao anterior, ignorado.\")\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criar relatório de detecção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = \"relatorio/relatorio_deteccao.txt\"\n",
    "with open(report_path, \"w\") as report_file:\n",
    "    report_file.write(\"Relatorio de Deteccao de Objetos Cortantes\\n\")\n",
    "    report_file.write(\"=\" * 50 + \"\\n\")\n",
    "    report_file.write(\"\\n\".join(detection_log))\n",
    "\n",
    "print(f\"Relatorio salvo em {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "Este notebook apresenta uma solução eficiente para detecção de objetos cortantes em vídeos. O modelo YOLOv8 é utilizado para identificar facas e tesouras, enquanto um mecanismo de comparação evita redundâncias. O envio de alertas por e-mail garante uma resposta rápida a eventos suspeitos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
